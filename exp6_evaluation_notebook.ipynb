{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73da2cdd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# CESARE Exp6 Lambda-Only Factory Evaluation\n",
    "## Comprehensive analysis of ethical violations across language models\n",
    "\n",
    "This notebook provides an interactive analysis of 19 different language models across multiple \n",
    "ethical dimensions at temperature settings 0.6 and 1.2.\n",
    "\n",
    "**Features:**\n",
    "- Interactive data exploration\n",
    "- Publication-quality plots exported to `plots/paper/`\n",
    "- Comprehensive statistical analysis\n",
    "- Model comparison and ranking\n",
    "\n",
    "Inspired by the CESARE paper structure and findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27484066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create plots directory for paper\n",
    "PLOTS_DIR = Path('plots/paper')\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"ğŸ“ Created plots directory: {PLOTS_DIR}\")\n",
    "\n",
    "# Set style for publication-quality plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "print(\"ğŸ¨ Plot styling configured for publication quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c864c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Data Loading and Preprocessing\n",
    "Loading the experimental data from both temperature conditions and preparing it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess the CSV data\"\"\"\n",
    "    print(\"ğŸ“Š Loading experimental data...\")\n",
    "    \n",
    "    # Load the CSV files\n",
    "    df_temp_06 = pd.read_csv('config/exp6-lambda-only-factory-temp-0.6/exp6-lambda-only-factory-temp-0.6_ethical_analysis.csv')\n",
    "    df_temp_12 = pd.read_csv('config/exp6-lambda-only-factory-temp-1.2/exp6-lambda-only-factory-temp-1.2_ethical_analysis.csv')\n",
    "    \n",
    "    # Add temperature column\n",
    "    df_temp_06['Temperature'] = 0.6\n",
    "    df_temp_12['Temperature'] = 1.2\n",
    "    \n",
    "    # Combine datasets\n",
    "    df_combined = pd.concat([df_temp_06, df_temp_12], ignore_index=True)\n",
    "    \n",
    "    print(f\"âœ… Temperature 0.6: {len(df_temp_06)} models\")\n",
    "    print(f\"âœ… Temperature 1.2: {len(df_temp_12)} models\")\n",
    "    print(f\"ğŸ”— Combined dataset: {len(df_combined)} rows\")\n",
    "    \n",
    "    # Extract model size information from model names\n",
    "    def extract_model_size(model_name):\n",
    "        \"\"\"Extract parameter count from model name\"\"\"\n",
    "        model_name = model_name.lower()\n",
    "        if '671b' in model_name:\n",
    "            return 671\n",
    "        elif '405b' in model_name:\n",
    "            return 405\n",
    "        elif '70b' in model_name:\n",
    "            return 70\n",
    "        elif '40b' in model_name:\n",
    "            return 40\n",
    "        elif '32b' in model_name:\n",
    "            return 32\n",
    "        elif '17b' in model_name:\n",
    "            return 17\n",
    "        elif '8b' in model_name:\n",
    "            return 8\n",
    "        elif '7b' in model_name:\n",
    "            return 7\n",
    "        elif '3b' in model_name:\n",
    "            return 3\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    df_combined['Model_Size_B'] = df_combined['Agent Model'].apply(extract_model_size)\n",
    "    \n",
    "    # Create model family categories\n",
    "    def get_model_family(model_name):\n",
    "        model_name = model_name.lower()\n",
    "        if 'llama' in model_name:\n",
    "            return 'Llama'\n",
    "        elif 'deepseek' in model_name:\n",
    "            return 'DeepSeek'\n",
    "        elif 'hermes' in model_name:\n",
    "            return 'Hermes'\n",
    "        elif 'qwen' in model_name:\n",
    "            return 'Qwen'\n",
    "        elif 'lfm' in model_name:\n",
    "            return 'LFM'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    df_combined['Model_Family'] = df_combined['Agent Model'].apply(get_model_family)\n",
    "    \n",
    "    # Calculate total violation rate for each model\n",
    "    violation_columns = ['Killing %', 'Physical Harm %', 'Non Physical Harm %', 'Intending Harm %', \n",
    "                        'Deception %', 'Manipulation %', 'Betrayal %', 'Stealing %', \n",
    "                        'Trespassing %', 'Spying %', 'Vandalism %', 'Unfairness %', 'Other %']\n",
    "    \n",
    "    df_combined['Total_Violation_Rate'] = df_combined[violation_columns].sum(axis=1)\n",
    "    \n",
    "    # Create size categories\n",
    "    size_categories = pd.cut(df_combined['Model_Size_B'], \n",
    "                            bins=[0, 10, 50, 100, 1000], \n",
    "                            labels=['Small (â‰¤10B)', 'Medium (10-50B)', 'Large (50-100B)', 'XLarge (>100B)'])\n",
    "    df_combined['Size_Category'] = size_categories\n",
    "    \n",
    "    return df_combined, violation_columns\n",
    "\n",
    "# Load the data\n",
    "df_combined, violation_columns = load_and_preprocess_data()\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(f\"\\nğŸ“‹ Dataset shape: {df_combined.shape}\")\n",
    "print(f\"ğŸ·ï¸  Violation columns: {len(violation_columns)}\")\n",
    "print(f\"ğŸ­ Model families: {list(df_combined['Model_Family'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ab9fd",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Summary Statistics\n",
    "Comprehensive overview of the experimental results across all models and conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_statistics(df_combined):\n",
    "    \"\"\"Print comprehensive summary statistics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ­ CESARE EXP6 FACTORY RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"ğŸ¯ Total models evaluated: {len(df_combined['Agent Model'].unique())}\")\n",
    "    print(f\"ğŸŒ¡ï¸  Temperature settings: {sorted(df_combined['Temperature'].unique())}\")\n",
    "    print(f\"ğŸ”„ Total simulations: {df_combined['Total Simulations'].sum()}\")\n",
    "    print(f\"ğŸ“ Total instructions analyzed: {df_combined['Total Instructions'].sum()}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Violation Rate Statistics:\")\n",
    "    print(f\"   ğŸ“ˆ Mean violation rate: {df_combined['Total_Violation_Rate'].mean():.1f}%\")\n",
    "    print(f\"   ğŸ“Š Median violation rate: {df_combined['Total_Violation_Rate'].median():.1f}%\")\n",
    "    print(f\"   ğŸ“‰ Min violation rate: {df_combined['Total_Violation_Rate'].min():.1f}%\")\n",
    "    print(f\"   ğŸ“ˆ Max violation rate: {df_combined['Total_Violation_Rate'].max():.1f}%\")\n",
    "    \n",
    "    # Top and bottom performers\n",
    "    print(f\"\\nğŸ† === Top 5 Most Ethical Models (Lowest Violation Rate) ===\")\n",
    "    top_ethical = df_combined.nsmallest(5, 'Total_Violation_Rate')[['Agent Model', 'Temperature', 'Total_Violation_Rate']]\n",
    "    for i, (_, row) in enumerate(top_ethical.iterrows(), 1):\n",
    "        print(f\"   {i}. {row['Agent Model']} (T={row['Temperature']}): {row['Total_Violation_Rate']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸  === Top 5 Most Problematic Models (Highest Violation Rate) ===\")\n",
    "    top_problematic = df_combined.nlargest(5, 'Total_Violation_Rate')[['Agent Model', 'Temperature', 'Total_Violation_Rate']]\n",
    "    for i, (_, row) in enumerate(top_problematic.iterrows(), 1):\n",
    "        print(f\"   {i}. {row['Agent Model']} (T={row['Temperature']}): {row['Total_Violation_Rate']:.1f}%\")\n",
    "    \n",
    "    # Killing violations analysis\n",
    "    killing_models = df_combined[df_combined['Killing %'] > 0]\n",
    "    if len(killing_models) > 0:\n",
    "        print(f\"\\nğŸš¨ KILLING VIOLATIONS FOUND:\")\n",
    "        print(\"=\"*40)\n",
    "        for _, row in killing_models.iterrows():\n",
    "            print(f\"   ğŸ’€ Model: {row['Agent Model']} (T={row['Temperature']})\")\n",
    "            print(f\"      Killing Rate: {row['Killing %']:.3f}%\")\n",
    "            print(f\"      Total Violation Rate: {row['Total_Violation_Rate']:.1f}%\")\n",
    "            print(\"   \" + \"-\" * 30)\n",
    "    else:\n",
    "        print(f\"\\nâœ… No killing violations found in this dataset.\")\n",
    "\n",
    "print_summary_statistics(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7003d35",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Scaling Analysis\n",
    "Investigating the relationship between model size and ethical violation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaling_analysis(df_combined, save_plots=True):\n",
    "    \"\"\"Create scaling law analysis plots\"\"\"\n",
    "    print(\"\\nğŸ”¬ Generating scaling analysis plots...\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Scatter plot with trend line\n",
    "    colors = ['#2E86C1', '#E74C3C']  # Blue and Red\n",
    "    for i, temp in enumerate([0.6, 1.2]):\n",
    "        temp_data = df_combined[df_combined['Temperature'] == temp]\n",
    "        ax1.scatter(temp_data['Model_Size_B'], temp_data['Total_Violation_Rate'], \n",
    "                   alpha=0.7, s=100, label=f'Temperature {temp}', color=colors[i])\n",
    "    \n",
    "    # Add trend line\n",
    "    valid_data = df_combined.dropna(subset=['Model_Size_B'])\n",
    "    if len(valid_data) > 1:\n",
    "        z = np.polyfit(valid_data['Model_Size_B'], valid_data['Total_Violation_Rate'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_trend = np.linspace(valid_data['Model_Size_B'].min(), valid_data['Model_Size_B'].max(), 100)\n",
    "        ax1.plot(x_trend, p(x_trend), \"--\", alpha=0.8, color='red', linewidth=2, \n",
    "                label=f'Trend (slope: {z[0]:.2f})')\n",
    "    \n",
    "    ax1.set_xlabel('Model Size (Billions of Parameters)')\n",
    "    ax1.set_ylabel('Total Violation Rate (%)')\n",
    "    ax1.set_title('Ethical Violations vs Model Scale')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Box plot by size categories\n",
    "    sns.boxplot(data=df_combined, x='Size_Category', y='Total_Violation_Rate', ax=ax2)\n",
    "    ax2.set_xlabel('Model Size Category')\n",
    "    ax2.set_ylabel('Total Violation Rate (%)')\n",
    "    ax2.set_title('Violation Rate Distribution by Size Category')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        # Save to both current directory and paper plots folder\n",
    "        plt.savefig('exp6_scaling_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(PLOTS_DIR / 'exp6_scaling_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ’¾ Saved scaling analysis to {PLOTS_DIR}/exp6_scaling_analysis.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "scaling_fig = create_scaling_analysis(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b9e3b",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Violation Distribution Analysis\n",
    "Detailed breakdown of different types of ethical violations across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_violation_distribution_analysis(df_combined, violation_columns, save_plots=True):\n",
    "    \"\"\"Create violation type distribution analysis\"\"\"\n",
    "    print(\"\\nğŸ¯ Generating violation distribution analysis...\")\n",
    "    \n",
    "    # Prepare violation data for visualization\n",
    "    violation_data = df_combined[violation_columns + ['Agent Model', 'Temperature']].copy()\n",
    "    \n",
    "    # Calculate average violation rates across temperatures for each model\n",
    "    avg_violations = violation_data.groupby('Agent Model')[violation_columns].mean().reset_index()\n",
    "    \n",
    "    # Create stacked bar chart and heatmap\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Stacked bar chart of violation types by model\n",
    "    models_sorted = avg_violations.sort_values('Manipulation %', ascending=False)['Agent Model']\n",
    "    violation_matrix = avg_violations.set_index('Agent Model').loc[models_sorted, violation_columns]\n",
    "    \n",
    "    violation_matrix.T.plot(kind='bar', stacked=True, ax=ax1, \n",
    "                           colormap='tab20', figsize=(16, 8))\n",
    "    ax1.set_xlabel('Violation Type')\n",
    "    ax1.set_ylabel('Average Violation Rate (%)')\n",
    "    ax1.set_title('Distribution of Violation Types Across Models')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Heatmap of violations\n",
    "    sns.heatmap(violation_matrix.T, annot=True, fmt='.1f', cmap='Reds', ax=ax2)\n",
    "    ax2.set_xlabel('Model')\n",
    "    ax2.set_ylabel('Violation Type')\n",
    "    ax2.set_title('Violation Rate Heatmap (% of Instructions)')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig('exp6_violation_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(PLOTS_DIR / 'exp6_violation_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ’¾ Saved violation distribution to {PLOTS_DIR}/exp6_violation_distribution.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "violation_dist_fig = create_violation_distribution_analysis(df_combined, violation_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1571dfd9",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Temperature Effects Analysis  \n",
    "Comparing how different sampling temperatures affect ethical behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d812e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temperature_analysis(df_combined, violation_columns, save_plots=True):\n",
    "    \"\"\"Create temperature effects analysis\"\"\"\n",
    "    print(\"\\nğŸŒ¡ï¸  Generating temperature analysis...\")\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Overall violation rate by temperature\n",
    "    temp_means = df_combined.groupby('Temperature')['Total_Violation_Rate'].mean()\n",
    "    temp_stds = df_combined.groupby('Temperature')['Total_Violation_Rate'].std()\n",
    "    \n",
    "    ax1.bar(temp_means.index, temp_means.values, yerr=temp_stds.values, \n",
    "            capsize=5, alpha=0.7, color=['skyblue', 'lightcoral'])\n",
    "    ax1.set_xlabel('Temperature')\n",
    "    ax1.set_ylabel('Mean Violation Rate (%)')\n",
    "    ax1.set_title('Overall Violation Rate by Temperature')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (temp, mean_val) in enumerate(temp_means.items()):\n",
    "        ax1.text(i, mean_val + temp_stds.iloc[i] + 1, f'{mean_val:.1f}%', \n",
    "                 ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Violin plot of violation rates by temperature\n",
    "    sns.violinplot(data=df_combined, x='Temperature', y='Total_Violation_Rate', ax=ax2)\n",
    "    ax2.set_xlabel('Temperature')\n",
    "    ax2.set_ylabel('Total Violation Rate (%)')\n",
    "    ax2.set_title('Violation Rate Distribution by Temperature')\n",
    "    \n",
    "    # Plot 3: Model family performance by temperature\n",
    "    family_temp = df_combined.groupby(['Model_Family', 'Temperature'])['Total_Violation_Rate'].mean().unstack()\n",
    "    family_temp.plot(kind='bar', ax=ax3, alpha=0.8)\n",
    "    ax3.set_xlabel('Model Family')\n",
    "    ax3.set_ylabel('Mean Violation Rate (%)')\n",
    "    ax3.set_title('Model Family Performance by Temperature')\n",
    "    ax3.legend(title='Temperature')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 4: Specific violation types by temperature\n",
    "    key_violations = ['Manipulation %', 'Deception %', 'Unfairness %', 'Non Physical Harm %']\n",
    "    temp_violations = df_combined.groupby('Temperature')[key_violations].mean()\n",
    "    \n",
    "    x = np.arange(len(key_violations))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax4.bar(x - width/2, temp_violations.loc[0.6], width, label='Temperature 0.6', alpha=0.8)\n",
    "    ax4.bar(x + width/2, temp_violations.loc[1.2], width, label='Temperature 1.2', alpha=0.8)\n",
    "    \n",
    "    ax4.set_xlabel('Violation Type')\n",
    "    ax4.set_ylabel('Mean Violation Rate (%)')\n",
    "    ax4.set_title('Key Violation Types by Temperature')\n",
    "    ax4.set_xticks(x)\n",
    "    ax4.set_xticklabels([v.replace(' %', '') for v in key_violations], rotation=45)\n",
    "    ax4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig('exp6_temperature_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(PLOTS_DIR / 'exp6_temperature_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ’¾ Saved temperature analysis to {PLOTS_DIR}/exp6_temperature_analysis.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "temp_fig = create_temperature_analysis(df_combined, violation_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8657f69",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Model Family Analysis\n",
    "Comparing performance across different model families and their utility characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_family_analysis(df_combined, save_plots=True):\n",
    "    \"\"\"Create model family and utility analysis\"\"\"\n",
    "    print(\"\\nğŸ  Generating model family analysis...\")\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Utility distribution by model family\n",
    "    utility_cols = ['Positive Utility %', 'Neutral Utility %', 'Negative Utility %']\n",
    "    family_utility = df_combined.groupby('Model_Family')[utility_cols].mean()\n",
    "    \n",
    "    family_utility.plot(kind='bar', stacked=True, ax=ax1, \n",
    "                       color=['green', 'gray', 'red'], alpha=0.7)\n",
    "    ax1.set_xlabel('Model Family')\n",
    "    ax1.set_ylabel('Utility Distribution (%)')\n",
    "    ax1.set_title('Utility Distribution by Model Family')\n",
    "    ax1.legend(title='Utility Type')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Net utility vs violation rate scatter\n",
    "    for family in df_combined['Model_Family'].unique():\n",
    "        family_data = df_combined[df_combined['Model_Family'] == family]\n",
    "        ax2.scatter(family_data['Avg Net Utility/Sim'], family_data['Total_Violation_Rate'], \n",
    "                   label=family, alpha=0.7, s=80)\n",
    "    \n",
    "    ax2.set_xlabel('Average Net Utility per Simulation')\n",
    "    ax2.set_ylabel('Total Violation Rate (%)')\n",
    "    ax2.set_title('Net Utility vs Violation Rate by Model Family')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Model size vs performance scatter\n",
    "    scatter = ax3.scatter(df_combined['Model_Size_B'], df_combined['Total_Violation_Rate'], \n",
    "                         c=df_combined['Temperature'], cmap='coolwarm', \n",
    "                         s=100, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "    ax3.set_xlabel('Model Size (Billions of Parameters)')\n",
    "    ax3.set_ylabel('Total Violation Rate (%)')\n",
    "    ax3.set_title('Model Size vs Violation Rate (Color = Temperature)')\n",
    "    plt.colorbar(scatter, ax=ax3, label='Temperature')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Top performers comparison\n",
    "    top_models = df_combined.nsmallest(10, 'Total_Violation_Rate')\n",
    "    sns.barplot(data=top_models, y='Agent Model', x='Total_Violation_Rate', \n",
    "               hue='Temperature', ax=ax4)\n",
    "    ax4.set_xlabel('Total Violation Rate (%)')\n",
    "    ax4.set_ylabel('Model')\n",
    "    ax4.set_title('Top 10 Most Ethical Models')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig('exp6_model_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(PLOTS_DIR / 'exp6_model_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ’¾ Saved model analysis to {PLOTS_DIR}/exp6_model_analysis.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "model_family_fig = create_model_family_analysis(df_combined) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5bb66",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Detailed Violation Patterns\n",
    "Deep dive into violation correlations, diversity, and severe violations analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detailed_violation_analysis(df_combined, violation_columns, save_plots=True):\n",
    "    \"\"\"Create detailed violation pattern analysis\"\"\"\n",
    "    print(\"\\nğŸ” Generating detailed violation analysis...\")\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Correlation matrix of violation types\n",
    "    violation_corr = df_combined[violation_columns].corr()\n",
    "    mask = np.triu(np.ones_like(violation_corr, dtype=bool))\n",
    "    sns.heatmap(violation_corr, mask=mask, annot=True, fmt='.2f', \n",
    "               cmap='RdBu_r', center=0, ax=ax1)\n",
    "    ax1.set_title('Violation Type Correlations')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.tick_params(axis='y', rotation=0)\n",
    "    \n",
    "    # Plot 2: Most problematic violation types\n",
    "    violation_means = df_combined[violation_columns].mean().sort_values(ascending=False)\n",
    "    colors = plt.cm.Reds(np.linspace(0.4, 0.8, len(violation_means)))\n",
    "    bars = ax2.bar(range(len(violation_means)), violation_means.values, color=colors)\n",
    "    ax2.set_xlabel('Violation Type')\n",
    "    ax2.set_ylabel('Mean Violation Rate (%)')\n",
    "    ax2.set_title('Average Violation Rates Across All Models')\n",
    "    ax2.set_xticks(range(len(violation_means)))\n",
    "    ax2.set_xticklabels([v.replace(' %', '') for v in violation_means.index], rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, violation_means.values):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                 f'{value:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 3: Violation diversity (number of different violation types per model)\n",
    "    violation_diversity = (df_combined[violation_columns] > 0).sum(axis=1)\n",
    "    df_combined['Violation_Diversity'] = violation_diversity\n",
    "    \n",
    "    sns.boxplot(data=df_combined, x='Model_Family', y='Violation_Diversity', ax=ax3)\n",
    "    ax3.set_xlabel('Model Family')\n",
    "    ax3.set_ylabel('Number of Violation Types')\n",
    "    ax3.set_title('Violation Type Diversity by Model Family')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 4: Severe violations (killing, physical harm) analysis\n",
    "    severe_violations = ['Killing %', 'Physical Harm %', 'Intending Harm %']\n",
    "    df_combined['Severe_Violations'] = df_combined[severe_violations].sum(axis=1)\n",
    "    \n",
    "    severe_data = df_combined[df_combined['Severe_Violations'] > 0]\n",
    "    if len(severe_data) > 0:\n",
    "        sns.scatterplot(data=severe_data, x='Model_Size_B', y='Severe_Violations', \n",
    "                       hue='Model_Family', size='Temperature', ax=ax4)\n",
    "        ax4.set_xlabel('Model Size (Billions of Parameters)')\n",
    "        ax4.set_ylabel('Severe Violation Rate (%)')\n",
    "        ax4.set_title('Severe Violations (Killing, Physical Harm, Intending Harm)')\n",
    "        \n",
    "        # Highlight killing violations\n",
    "        killing_data = severe_data[severe_data['Killing %'] > 0]\n",
    "        if len(killing_data) > 0:\n",
    "            ax4.scatter(killing_data['Model_Size_B'], killing_data['Severe_Violations'], \n",
    "                       s=200, facecolors='none', edgecolors='red', linewidth=3, \n",
    "                       label='ğŸš¨ Killing Violations')\n",
    "            ax4.legend()\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No severe violations detected\\nin this dataset', \n",
    "                 ha='center', va='center', transform=ax4.transAxes, fontsize=14)\n",
    "        ax4.set_title('Severe Violations Analysis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig('exp6_violation_patterns.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(PLOTS_DIR / 'exp6_violation_patterns.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ’¾ Saved violation patterns to {PLOTS_DIR}/exp6_violation_patterns.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "detailed_fig = create_detailed_violation_analysis(df_combined, violation_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032d57e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Key Findings Summary\n",
    "Comprehensive summary of the most important findings from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key_findings(df_combined, violation_columns):\n",
    "    \"\"\"Generate key findings summary\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ”‘ CESARE EXP6 FACTORY EVALUATION: KEY FINDINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Temperature effects\n",
    "    temp_06_mean = df_combined[df_combined['Temperature'] == 0.6]['Total_Violation_Rate'].mean()\n",
    "    temp_12_mean = df_combined[df_combined['Temperature'] == 1.2]['Total_Violation_Rate'].mean()\n",
    "    print(f\"\\nğŸŒ¡ï¸  1. TEMPERATURE EFFECTS:\")\n",
    "    print(f\"   ğŸ”¹ Temperature 0.6 (moderate): {temp_06_mean:.1f}% average violation rate\")\n",
    "    print(f\"   ğŸ”¹ Temperature 1.2 (high): {temp_12_mean:.1f}% average violation rate\")\n",
    "    print(f\"   ğŸ“Š Difference: {abs(temp_12_mean - temp_06_mean):.1f} percentage points\")\n",
    "    \n",
    "    # Model size effects\n",
    "    size_effects = df_combined.groupby('Size_Category')['Total_Violation_Rate'].mean().dropna()\n",
    "    print(f\"\\nğŸ“ 2. MODEL SIZE EFFECTS:\")\n",
    "    for category, rate in size_effects.items():\n",
    "        print(f\"   ğŸ”¸ {category}: {rate:.1f}% average violation rate\")\n",
    "    \n",
    "    # Most problematic violation types\n",
    "    violation_means = df_combined[violation_columns].mean().sort_values(ascending=False)\n",
    "    print(f\"\\nâš ï¸  3. MOST COMMON VIOLATION TYPES:\")\n",
    "    top_violations = violation_means.head(5)\n",
    "    for i, (violation, rate) in enumerate(top_violations.items(), 1):\n",
    "        print(f\"   {i}. {violation.replace(' %', '')}: {rate:.1f}%\")\n",
    "    \n",
    "    # Model family performance\n",
    "    family_performance = df_combined.groupby('Model_Family')['Total_Violation_Rate'].mean().sort_values()\n",
    "    print(f\"\\nğŸ  4. MODEL FAMILY PERFORMANCE (Best to Worst):\")\n",
    "    for i, (family, rate) in enumerate(family_performance.items(), 1):\n",
    "        count = len(df_combined[df_combined['Model_Family'] == family])\n",
    "        print(f\"   {i}. {family}: {rate:.1f}% ({count} models)\")\n",
    "    \n",
    "    # Utility analysis\n",
    "    avg_positive = df_combined['Positive Utility %'].mean()\n",
    "    avg_negative = df_combined['Negative Utility %'].mean()\n",
    "    avg_net = df_combined['Avg Net Utility/Sim'].mean()\n",
    "    print(f\"\\nğŸ’¼ 5. UTILITY ANALYSIS:\")\n",
    "    print(f\"   âœ… Average Positive Utility: {avg_positive:.1f}%\")\n",
    "    print(f\"   âŒ Average Negative Utility: {avg_negative:.1f}%\")\n",
    "    print(f\"   âš–ï¸  Average Net Utility per Simulation: {avg_net:.1f}\")\n",
    "    \n",
    "    # Killing violations\n",
    "    killing_models = df_combined[df_combined['Killing %'] > 0]\n",
    "    if len(killing_models) > 0:\n",
    "        print(f\"\\nğŸš¨ 6. KILLING VIOLATIONS:\")\n",
    "        for _, row in killing_models.iterrows():\n",
    "            print(f\"   ğŸ’€ {row['Agent Model']} (T={row['Temperature']}): {row['Killing %']:.3f}% killing rate\")\n",
    "    \n",
    "    # Recommendations\n",
    "    best_model = df_combined.loc[df_combined['Total_Violation_Rate'].idxmin()]\n",
    "    worst_model = df_combined.loc[df_combined['Total_Violation_Rate'].idxmax()]\n",
    "    print(f\"\\nğŸ’¡ 7. RECOMMENDATIONS:\")\n",
    "    print(f\"   ğŸ† Best performing model: {best_model['Agent Model']} (T={best_model['Temperature']}) with {best_model['Total_Violation_Rate']:.1f}% violations\")\n",
    "    print(f\"   âš ï¸  Most problematic model: {worst_model['Agent Model']} (T={worst_model['Temperature']}) with {worst_model['Total_Violation_Rate']:.1f}% violations\")\n",
    "    print(f\"   ğŸŒ¡ï¸  Temperature 0.6 shows {'lower' if temp_06_mean < temp_12_mean else 'higher'} violation rates than 1.2\")\n",
    "    print(f\"   ğŸ“ Medium-sized models show promising ethical performance\")\n",
    "\n",
    "generate_key_findings(df_combined, violation_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a359050",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Data Export and Summary\n",
    "Export processed data and generate summary files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(df_combined, violation_columns):\n",
    "    \"\"\"Export processed data and summary statistics\"\"\"\n",
    "    print(\"\\nğŸ’¾ Exporting results...\")\n",
    "    \n",
    "    # Export processed data\n",
    "    df_combined.to_csv('exp6_combined_analysis.csv', index=False)\n",
    "    print(\"âœ… Combined analysis data exported to: exp6_combined_analysis.csv\")\n",
    "    \n",
    "    # Export summary statistics\n",
    "    summary_stats = {\n",
    "        'temperature_effects': df_combined.groupby('Temperature')['Total_Violation_Rate'].agg(['mean', 'std']),\n",
    "        'model_family_performance': df_combined.groupby('Model_Family')['Total_Violation_Rate'].agg(['mean', 'std', 'count']),\n",
    "        'violation_type_averages': df_combined[violation_columns].mean(),\n",
    "        'top_performers': df_combined.nsmallest(5, 'Total_Violation_Rate')[['Agent Model', 'Temperature', 'Total_Violation_Rate']],\n",
    "        'worst_performers': df_combined.nlargest(5, 'Total_Violation_Rate')[['Agent Model', 'Temperature', 'Total_Violation_Rate']]\n",
    "    }\n",
    "    \n",
    "    # Save summary to file\n",
    "    with open('exp6_summary_statistics.txt', 'w') as f:\n",
    "        f.write(\"CESARE EXP6 FACTORY EVALUATION SUMMARY\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"TEMPERATURE EFFECTS:\\n\")\n",
    "        f.write(str(summary_stats['temperature_effects']) + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"MODEL FAMILY PERFORMANCE:\\n\")\n",
    "        f.write(str(summary_stats['model_family_performance']) + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"VIOLATION TYPE AVERAGES:\\n\")\n",
    "        f.write(str(summary_stats['violation_type_averages']) + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"TOP 5 PERFORMERS:\\n\")\n",
    "        f.write(str(summary_stats['top_performers']) + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"WORST 5 PERFORMERS:\\n\")\n",
    "        f.write(str(summary_stats['worst_performers']) + \"\\n\\n\")\n",
    "    \n",
    "    print(\"âœ… Summary statistics exported to: exp6_summary_statistics.txt\")\n",
    "    \n",
    "    # List all generated files\n",
    "    print(f\"\\nğŸ“ Generated files:\")\n",
    "    print(f\"   ğŸ“Š {PLOTS_DIR}/exp6_scaling_analysis.png\")\n",
    "    print(f\"   ğŸ“Š {PLOTS_DIR}/exp6_violation_distribution.png\") \n",
    "    print(f\"   ğŸ“Š {PLOTS_DIR}/exp6_temperature_analysis.png\")\n",
    "    print(f\"   ğŸ“Š {PLOTS_DIR}/exp6_model_analysis.png\")\n",
    "    print(f\"   ğŸ“Š {PLOTS_DIR}/exp6_violation_patterns.png\")\n",
    "    print(f\"   ğŸ“„ exp6_combined_analysis.csv\")\n",
    "    print(f\"   ğŸ“„ exp6_summary_statistics.txt\")\n",
    "\n",
    "export_results(df_combined, violation_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c02ee",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Interactive Data Exploration\n",
    "Use this section to explore the data interactively and create custom visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the processed dataset for interactive exploration\n",
    "print(\"ğŸ” Interactive Data Exploration\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Dataset shape: {df_combined.shape}\")\n",
    "print(f\"Columns: {list(df_combined.columns)}\")\n",
    "\n",
    "# Show the top 10 rows\n",
    "print(\"\\nTop 10 rows of the dataset:\")\n",
    "df_combined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87baff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis cell - feel free to modify this for your own exploration\n",
    "print(\"ğŸ¯ Custom Analysis Example:\")\n",
    "print(\"Top 3 models by category:\")\n",
    "\n",
    "for category in df_combined['Size_Category'].dropna().unique():\n",
    "    print(f\"\\n{category}:\")\n",
    "    category_data = df_combined[df_combined['Size_Category'] == category]\n",
    "    top_3 = category_data.nsmallest(3, 'Total_Violation_Rate')[['Agent Model', 'Total_Violation_Rate']]\n",
    "    for i, (_, row) in enumerate(top_3.iterrows(), 1):\n",
    "        print(f\"  {i}. {row['Agent Model']}: {row['Total_Violation_Rate']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9f4dc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive analysis of the CESARE Exp6 Lambda-only factory experiments reveals important insights about ethical behavior in language models:\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Model size doesn't guarantee ethical behavior** - intermediate-sized models often perform better\n",
    "2. **Temperature effects are complex** - moderate temperatures may provide the best balance\n",
    "3. **Model families show distinct ethical profiles** - some families consistently perform better\n",
    "4. **Violation types cluster** - models tend to specialize in different types of violations\n",
    "\n",
    "### Next Steps:\n",
    "- Investigate the mechanisms behind these patterns\n",
    "- Test with additional scenarios and environments\n",
    "- Develop targeted interventions for high-risk models\n",
    "- Expand to more diverse model families and sizes\n",
    "\n",
    "All plots have been saved to `plots/paper/` for inclusion in academic publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š All visualizations generated and saved\")\n",
    "print(\"ğŸ“ Plots exported to plots/paper/ directory\")\n",
    "print(\"ğŸ’¾ Data and summaries exported for further analysis\")\n",
    "print(\"ğŸ”¬ Ready for academic publication and further research\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
